{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Linear Model\n",
    "\"Regression analysis generates an equation to describe the statistical relationship between one or more predictor variables and the response variable.\" That's a quote from the documentation from an old statistical package called minitab. It's wordy, but what it's basically saying is that creating the model is just the beginning. The interpretation of the results is the important part. \n",
    "\n",
    "We left off on our last tutorial by plotting the line of best fit. So at this point, we know how to instantiate the model, draw a line of best fit, and use our model to make predictions. \n",
    "\n",
    "Let's import our model from the lab: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "df_x = pd.DataFrame(diabetes.data,\n",
    "                 columns=diabetes.feature_names)\n",
    "df_y = pd.DataFrame(diabetes.target,\n",
    "                 columns=[\"diabetes\"])\n",
    "\n",
    "# split into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=42)\n",
    "\n",
    "# instantiate the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept=True,\n",
    "                        n_jobs=4)\n",
    "\n",
    "# train\n",
    "fit = model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Error\n",
    "There are three main error metrics used to evaluate linear regression model; Mean Absolute Error, Root Mean Squared Error and R2 score.\n",
    "\n",
    "### Mean Absolute Error\n",
    "Since we have our line of best fit, we can measure the distance between each point and the line to calculate the error (residuals). Because this measurement can be either positive or negative, we take the absolute value of each value so the effects of the signs don't cancel each other out, and sum the values, then take the average. \n",
    "\n",
    "![mae](mae.png)\n",
    "\n",
    "#### Manual Steps for calculating MSE\n",
    "1. Measure the distance between each point and the line of best fit\n",
    "2. Take the absolute value of the error at each data point\n",
    "3. Calculate the mean\n",
    "\n",
    "This is the easiset measurment to understand intuitively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.79389304196525"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE represents the average error between our two values, and measures the magnitued of the error. Because we've taken the absolute value of the error, we are unable to determine the direction. \n",
    "- 0 MAE means there is no error\n",
    "- The upper bound depends on the range of your dataset\n",
    "- To compare MAE into different models, you can convert this score into a percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE\n",
    "For mean squared error we sum the squares of the differences instead of the absolute values. And then we take the square root of that result: \n",
    "![rmse](rmse.gif)\n",
    "\n",
    "Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. Meaning that this is the better measurement to use when you want to penazlize large errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, preds) # calculate mean squared error\n",
    "rmse = np.sqrt(mse) # calcualate root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.8532569849144"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most popular metric because it penalizes large errors, giving a more representative error metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Score- Coefficient of Determination\n",
    "This metric is called the **R Squared Goodness of Fit** and determines the percentage of the variance in the dependent variable that can be explained by the independent variables. \n",
    "\n",
    "![r2](r2.png)\n",
    "\n",
    "- R-squared is always between 0 and 100\n",
    "- 0% represents a model that does not explain any of the variation in the response variable\n",
    "- 100% represents a model that explains all of the variation in the response variable \n",
    "- the larger the R2, the better the regression model fits your observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.452606602161738"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
